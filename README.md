# RAG-Research-Technion

## ðŸš€ Overview

**RAG-Research-Technion** is an advanced **Retrieval-Augmented Generation (RAG) system** designed to enhance Large Language Model (LLM) responses by dynamically retrieving relevant context from external knowledge sources. By leveraging **LangChain**, **ChromaDB**, and **vector search**, the system improves **domain-specific question answering and reasoning**.

This project integrates ** open-source Foundation models LLMs** such as:
- **Mistral 7B**
- **Orca 2 7B**
- **Llama 2 13B**
- **Gemma 2 2B**

## ðŸ”§ Features

- **Contextual RAG Implementation**: Retrieves domain-specific knowledge before generating responses.
- **Vector Search with ChromaDB**: Uses **semantic search** to fetch **highly relevant documents**.
- **LangChain Orchestration**: Implements **document retrieval, prompt engineering, and structured LLM execution**.
- **Multi-Model Benchmarking**: Evaluates different **LLMs with and without RAG** for comparative analysis.
- **Chain-of-Thought (CoT) Reasoning**: Guides models to **think in structured steps** for better decision-making.
- **Efficient Document Filtering**: Uses **LLM-as-a-Judge** to reduce noise in retrieved context.

## ðŸ“‚ Repository Structure


